% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/foceiFit.R
\name{foceiControl}
\alias{foceiControl}
\title{Control Options for FOCEi}
\usage{
foceiControl(sigdig = 4, epsilon = NULL, maxInnerIterations = 1000,
  maxOuterIterations = 5000, n1qn1nsim = NULL, method = c("liblsoda",
  "lsoda", "dop853"), transitAbs = NULL, atol = NULL, rtol = NULL,
  maxstepsOde = 5000L, hmin = 0L, hmax = NULL, hini = 0,
  maxordn = 12L, maxords = 5L, cores, covsInterpolation = c("linear",
  "locf", "nocb", "midpoint"), printInner = 0L, print = 1L,
  printNcol = 8L, scaleTo = 1, scaleObjective = 1, derivEps = c(1e-05,
  1e-05), derivMethod = c("forward", "central"),
  covDerivMethod = c("forward", "central"), covMethod = c("r,s", "r", "s",
  ""), lbfgsLmm = 50L, lbfgsPgtol = 0, lbfgsFactr = NULL, eigen = TRUE,
  addPosthoc = TRUE, diagXform = c("sqrt", "log", "identity"),
  sumProd = FALSE, optExpression = TRUE, ci = 0.95,
  useColor = crayon::has_color(), boundTol = NULL, calcTables = TRUE, ...,
  stiff)
}
\arguments{
\item{sigdig}{Optimization significant digits. This controls:

 Defaults for optimization and ODE solving

 The tolerance of the inner and outer optimization is \code{10^-sigdig}

 The tolerance of the ODE solvers is \code{10^(-sigdig-1)}

 The significant figures that some tables are rounded to.}

\item{epsilon}{Precision of estimate for n1qn1 optimization.}

\item{maxInnerIterations}{Number of iterations for n1qn1
optimization.}

\item{maxOuterIterations}{Maximum number of L-BFGS-B optimization
for outer problem.}

\item{n1qn1nsim}{Number of function evaluations for n1qn1
optimization.}

\item{maxstepsOde}{Maximum number of steps for ODE solver.}

\item{printInner}{Integer representing when the inner step is
printed. By default this is 0 or do not print.  1 is print
every function evaluation, 5 is print every 5 evaluations.}

\item{print}{Integer representing when the outer step is
printed. When this is 0 or do not print the iterations.  1 is
print every function evaluation (default), 5 is print every 5
evaluations.}

\item{scaleTo}{Scale the initial parameter estimate to this value.
By default this is 1.  When zero or below, no scaling is performed.}

\item{scaleObjective}{Scale the initial objective function to this
    value.  By default this is 1.  When \code{scaleObjective} is
    greater than zero, this scaling is performed by:

     \code{scaledObj = currentObj / |initialObj| * scaleObjective}

    Therefore, if the initial objective function is negative, the
    initial scaled objective function would be negative as well.
    When \code{scaleObjective} is less than zero, no scaling is
    performed.}

\item{derivEps}{Central/Forward difference tolerances, which is a
    vector of relative difference and absolute difference.  The
    central/forward difference step size h is calculated as:

        \code{h = abs(x)*derivEps[1] + derivEps[2]}}

\item{derivMethod}{indicates the method for calculating
derivatives of the outer problem.  Currently supports
"central" and "forward" difference methods.}

\item{covDerivMethod}{indicates the method for calculating the
derivatives while calculating the covariance components
(Hessian and S).}

\item{covMethod}{Method for calculating covariance.  In this
    discussion, R is the Hessian matrix of the objective
    function. The S matrix is the sum of each individual's
    gradient cross-product (evaluated at the individual empirical
    Bayes estimates).

 "\code{r,s}" Uses the sandwich matrix to calculate the covariance, that is: \eqn{R^-1 \times S \times R^-1}

 "\code{r}" Uses the Hessian matrix to calculate the covariance as \eqn{2\times R^-1}

 "\code{s}" Uses the crossproduct matrix to calculate the covariance as \eqn{4\times S^-1}

 "" Does not calculate the covariance step.}

\item{lbfgsLmm}{An integer giving the number of BFGS updates
retained in the "L-BFGS-B" method, It defaults to 40.}

\item{lbfgsPgtol}{is a double precision variable.

    On entry pgtol >= 0 is specified by the user.  The iteration
    will stop when:

       \code{max{|proj g_i | i = 1, ..., n} <= lbfgsPgtol}

    where pg_i is the ith component of the projected gradient.

    On exit pgtol is unchanged.  This defaults to zero, when the
    check is suppressed.}

\item{lbfgsFactr}{Controls the convergence of the "L-BFGS-B"
method.  Convergence occurs when the reduction in the
objective is within this factor of the machine
tolerance. Default is 1e10, which gives a tolerance of about
\code{2e-6}, approximately 4 sigdigs.  You can check your
exact tolerance by multiplying this value by
\code{.Machine$double.eps}}

\item{eigen}{A boolean indicating if eigenvectors are calculated
to include a condition number calculation.}

\item{addPosthoc}{Boolean indicating if posthoc parameters are
added to the table output.}

\item{diagXform}{This is the transformation used on the diagonal
    of the \code{chol(inv(omega))}. This matrix and values are the
    parameters estimated in FOCEi. The possibilities are:

 \code{sqrt} Estimates the sqrt of the diagonal elements of \code{chol(inv(omega))}.  This is the default method.

 \code{log} Estimates the log of the diagonal elements of \code{chol(inv(omega))}

 \code{identity} Estimates the diagonal elements without any transformations}

\item{sumProd}{Is a boolean indicating if the model should change
multiplication to high precision multiplication and sums to
high precision sums using the PreciseSums package.  By default
this is \code{FALSE}.}

\item{optExpression}{Optimize the RxODE expression to speed up
calculation. By default this is turned on.}

\item{ci}{Confidence level for some tables.  By default this is
0.95 or 95% confidence.}

\item{...}{Ignored parameters}
}
\description{
Control Options for FOCEi
}
\details{
Note this uses the R's L-BFGS-B in \code{\link{optim}} for the
outer problem and the BFGS \code{\link[n1qn1]{n1qn1}} with that
allows restoring the prior individual Hessian (for faster
optimization speed).

By default FOCEi scales the outer problem parameters to 1.0 for
the initial parameter estimates and scales the objective function
to 1.0, as suggested by the
\href{https://www.nag.com/numeric/fl/nagdoc_fl25/html/e04/e04intro.html}{NAG library}
and \href{scipy}{https://www.scipy-lectures.org/advanced/mathematical_optimization/}.

However the inner problem is not scaled.  Since most eta estimates
start near zero, scaling for these parameters do not make sense.

This process of scaling can fix some ill conditioning for the
unscaled problem.  The covariance step is performed on the
unscaled problem, so the condition number of that matrix may not
be reflective of the scaled problem's condition-number.
}
\seealso{
\code{\link{optim}}

\code{\link[n1qn1]{n1qn1}}
}
\author{
Matthew L. Fidler
}
